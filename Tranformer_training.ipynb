{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19UgM8pc6IXM",
        "outputId": "9ab17ce6-fef7-4cb3-f7ba-fb59bc3a69e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'nanoGPT'...\n",
            "remote: Enumerating objects: 689, done.\u001b[K\n",
            "remote: Total 689 (delta 0), reused 0 (delta 0), pack-reused 689 (from 1)\u001b[K\n",
            "Receiving objects: 100% (689/689), 975.24 KiB | 7.74 MiB/s, done.\n",
            "Resolving deltas: 100% (382/382), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/karpathy/nanoGPT.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ApXkFBBC6QzE"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "cd /content/nanoGPT\n",
        "mkdir -p data/abc\n",
        "\n",
        "\n",
        "ln -s /content/drive/MyDrive/train.bin data/abc/train.bin\n",
        "ln -s /content/drive/MyDrive/val.bin   data/abc/val.bin\n",
        "ln -s /content/drive/MyDrive/meta.pkl  data/abc/meta.pkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5RL7OOxCRWee"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "msAov2xKKDKP"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "cd /content/nanoGPT\n",
        "cat << 'EOF' > config/abc_tiny.py\n",
        "# config/abc_tiny.py\n",
        "# Tiny GPT (~1M params) — 200M token run\n",
        "\n",
        "out_dir = '/content/drive/MyDrive/nanoGPT_runs/out-abc-tiny'\n",
        "eval_interval = 1000\n",
        "eval_iters = 200\n",
        "log_interval = 200\n",
        "always_save_checkpoint = True\n",
        "\n",
        "dataset = 'abc'\n",
        "\n",
        "# ---- batching ----\n",
        "block_size = 256\n",
        "batch_size = 8\n",
        "gradient_accumulation_steps = 16\n",
        "# tokens/iter = 32768\n",
        "\n",
        "# ---- model (~1M params) ----\n",
        "n_layer = 4\n",
        "n_head  = 4\n",
        "n_embd  = 144\n",
        "dropout = 0.1\n",
        "\n",
        "# ---- training (200M tokens = 1 epoch) ----\n",
        "learning_rate = 3e-4\n",
        "max_iters = 6104\n",
        "lr_decay_iters = 6104\n",
        "warmup_iters = 500\n",
        "min_lr = 1e-5\n",
        "\n",
        "weight_decay = 1e-1\n",
        "beta1 = 0.9\n",
        "beta2 = 0.95\n",
        "grad_clip = 1.0\n",
        "\n",
        "device = 'cuda'\n",
        "dtype = 'float16'\n",
        "compile = False\n",
        "EOF\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAIB15dORXja",
        "outputId": "2a086c2b-4119-4ec1-8b46-a4ccdf142ebb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overriding config with config/abc_tiny.py:\n",
            "# config/abc_tiny.py\n",
            "# Tiny GPT (~1M params) — 200M token run\n",
            "\n",
            "out_dir = '/content/drive/MyDrive/nanoGPT_runs/out-abc-tiny'\n",
            "eval_interval = 1000\n",
            "eval_iters = 200\n",
            "log_interval = 200\n",
            "always_save_checkpoint = True\n",
            "\n",
            "dataset = 'abc'\n",
            "\n",
            "# ---- batching ----\n",
            "block_size = 256\n",
            "batch_size = 8\n",
            "gradient_accumulation_steps = 16\n",
            "# tokens/iter = 32768\n",
            "\n",
            "# ---- model (~1M params) ----\n",
            "n_layer = 4\n",
            "n_head  = 4\n",
            "n_embd  = 144\n",
            "dropout = 0.1\n",
            "\n",
            "# ---- training (200M tokens = 1 epoch) ----\n",
            "learning_rate = 3e-4\n",
            "max_iters = 6104\n",
            "lr_decay_iters = 6104\n",
            "warmup_iters = 500\n",
            "min_lr = 1e-5\n",
            "\n",
            "weight_decay = 1e-1\n",
            "beta1 = 0.9\n",
            "beta2 = 0.95\n",
            "grad_clip = 1.0\n",
            "\n",
            "device = 'cuda'\n",
            "dtype = 'float16'\n",
            "compile = False\n",
            "\n",
            "tokens per iteration will be: 32,768\n",
            "found vocab_size = 99 (inside data/abc/meta.pkl)\n",
            "Initializing a new model from scratch\n",
            "number of parameters: 1.01M\n",
            "num decayed parameter tensors: 18, with 1,046,448 parameters\n",
            "num non-decayed parameter tensors: 9, with 1,296 parameters\n",
            "using fused AdamW: True\n",
            "step 0: train loss 4.5915, val loss 4.5914\n",
            "iter 0: loss 4.5714, time 92739.19ms, mfu -100.00%\n",
            "iter 200: loss 1.8991, time 1217.83ms, mfu 0.07%\n",
            "iter 400: loss 1.7459, time 362.95ms, mfu 0.08%\n",
            "iter 600: loss 1.1660, time 379.78ms, mfu 0.10%\n",
            "iter 800: loss 1.1209, time 627.09ms, mfu 0.10%\n",
            "step 1000: train loss 0.9969, val loss 0.9755\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_runs/out-abc-tiny\n",
            "iter 1000: loss 1.0685, time 5782.16ms, mfu 0.09%\n",
            "iter 1200: loss 0.9172, time 209.33ms, mfu 0.12%\n",
            "iter 1400: loss 1.0884, time 213.52ms, mfu 0.15%\n",
            "iter 1600: loss 0.8526, time 224.12ms, mfu 0.17%\n",
            "iter 1800: loss 0.8307, time 208.48ms, mfu 0.19%\n",
            "step 2000: train loss 0.7313, val loss 0.7373\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_runs/out-abc-tiny\n",
            "iter 2000: loss 1.0254, time 2875.91ms, mfu 0.18%\n",
            "iter 2200: loss 0.9394, time 209.71ms, mfu 0.20%\n",
            "iter 2400: loss 0.8437, time 200.05ms, mfu 0.22%\n",
            "iter 2600: loss 0.8067, time 202.93ms, mfu 0.24%\n",
            "iter 2800: loss 0.7337, time 204.38ms, mfu 0.25%\n",
            "step 3000: train loss 0.6702, val loss 0.6572\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_runs/out-abc-tiny\n",
            "iter 3000: loss 0.9019, time 2755.35ms, mfu 0.23%\n",
            "iter 3200: loss 0.7357, time 200.82ms, mfu 0.25%\n",
            "iter 3400: loss 0.7497, time 413.61ms, mfu 0.24%\n",
            "iter 3600: loss 0.7165, time 202.17ms, mfu 0.26%\n",
            "iter 3800: loss 0.8392, time 199.87ms, mfu 0.28%\n",
            "step 4000: train loss 0.6122, val loss 0.6310\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_runs/out-abc-tiny\n",
            "iter 4000: loss 0.6538, time 2761.16ms, mfu 0.25%\n",
            "iter 4200: loss 0.7608, time 198.59ms, mfu 0.27%\n",
            "iter 4400: loss 0.5221, time 202.42ms, mfu 0.28%\n",
            "iter 4600: loss 0.5941, time 200.98ms, mfu 0.29%\n",
            "iter 4800: loss 0.7308, time 201.32ms, mfu 0.31%\n",
            "step 5000: train loss 0.5948, val loss 0.5963\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_runs/out-abc-tiny\n",
            "iter 5000: loss 0.7047, time 3020.87ms, mfu 0.28%\n",
            "iter 5200: loss 0.6209, time 209.00ms, mfu 0.29%\n",
            "iter 5400: loss 0.8280, time 216.95ms, mfu 0.30%\n",
            "iter 5600: loss 0.6553, time 215.64ms, mfu 0.31%\n",
            "iter 5800: loss 0.5473, time 211.65ms, mfu 0.31%\n",
            "step 6000: train loss 0.6067, val loss 0.5894\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_runs/out-abc-tiny\n",
            "iter 6000: loss 0.6429, time 2796.02ms, mfu 0.29%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/backends/__init__.py:46: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
            "  self.setter(val)\n",
            "/content/nanoGPT/train.py:196: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "cd /content/nanoGPT\n",
        "python -u train.py config/abc_tiny.py | tee /content/drive/MyDrive/tiny.log\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfKBVGFRowau",
        "outputId": "8d6a5367-a26b-45f8-aeae-9abd408dac45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sat Dec 13 07:37:20 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P0             43W /  400W |       0MiB /  40960MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ztB61H8Io2Sp"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "cd /content/nanoGPT\n",
        "cat << 'EOF' > config/abc_large.py\n",
        "# config/abc_large.py\n",
        "# Large GPT (~50M parameters, 24 layers)\n",
        "\n",
        "# -------------------\n",
        "# Output & logging\n",
        "# -------------------\n",
        "out_dir = '/content/drive/MyDrive/nanoGPT_runs/out-abc-large'\n",
        "eval_interval = 1000\n",
        "eval_iters = 200\n",
        "log_interval = 200\n",
        "always_save_checkpoint = True\n",
        "\n",
        "# -------------------\n",
        "# Dataset\n",
        "# -------------------\n",
        "dataset = 'abc'\n",
        "\n",
        "# -------------------\n",
        "# Batch / streaming\n",
        "# -------------------\n",
        "block_size = 256\n",
        "batch_size = 8\n",
        "gradient_accumulation_steps = 16\n",
        "# Effective tokens / iteration = 32768\n",
        "\n",
        "# -------------------\n",
        "# Model (~50M params)\n",
        "# -------------------\n",
        "n_layer = 24\n",
        "n_head  = 16\n",
        "n_embd  = 512\n",
        "dropout = 0.1\n",
        "\n",
        "# -------------------\n",
        "# Training (1 epoch = 200M tokens)\n",
        "# -------------------\n",
        "learning_rate = 3e-4\n",
        "max_iters = 6104\n",
        "lr_decay_iters = max_iters\n",
        "warmup_iters = 500\n",
        "min_lr = 1e-5\n",
        "\n",
        "weight_decay = 1e-1\n",
        "beta1 = 0.9\n",
        "beta2 = 0.95\n",
        "grad_clip = 1.0\n",
        "\n",
        "# -------------------\n",
        "# System\n",
        "# -------------------\n",
        "device = 'cuda'\n",
        "dtype = 'float16'\n",
        "compile = False\n",
        "EOF\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gThH4UDPo36y",
        "outputId": "963999f2-b81e-4c0f-ec77-47e089ec8aa5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overriding config with config/abc_large.py:\n",
            "# config/abc_large.py\n",
            "# Large GPT (~50M parameters, 24 layers)\n",
            "\n",
            "# -------------------\n",
            "# Output & logging\n",
            "# -------------------\n",
            "out_dir = '/content/drive/MyDrive/nanoGPT_runs/out-abc-large'\n",
            "eval_interval = 1000\n",
            "eval_iters = 200\n",
            "log_interval = 200\n",
            "always_save_checkpoint = True\n",
            "\n",
            "# -------------------\n",
            "# Dataset\n",
            "# -------------------\n",
            "dataset = 'abc'\n",
            "\n",
            "# -------------------\n",
            "# Batch / streaming\n",
            "# -------------------\n",
            "block_size = 256\n",
            "batch_size = 8\n",
            "gradient_accumulation_steps = 16\n",
            "# Effective tokens / iteration = 32768\n",
            "\n",
            "# -------------------\n",
            "# Model (~50M params)\n",
            "# -------------------\n",
            "n_layer = 24\n",
            "n_head  = 16\n",
            "n_embd  = 512\n",
            "dropout = 0.1\n",
            "\n",
            "# -------------------\n",
            "# Training (1 epoch = 200M tokens)\n",
            "# -------------------\n",
            "learning_rate = 3e-4\n",
            "max_iters = 6104\n",
            "lr_decay_iters = max_iters\n",
            "warmup_iters = 500\n",
            "min_lr = 1e-5\n",
            "\n",
            "weight_decay = 1e-1\n",
            "beta1 = 0.9\n",
            "beta2 = 0.95\n",
            "grad_clip = 1.0\n",
            "\n",
            "# -------------------\n",
            "# System\n",
            "# -------------------\n",
            "device = 'cuda'\n",
            "dtype = 'float16'\n",
            "compile = False\n",
            "\n",
            "tokens per iteration will be: 32,768\n",
            "found vocab_size = 99 (inside data/abc/meta.pkl)\n",
            "Initializing a new model from scratch\n",
            "number of parameters: 75.57M\n",
            "num decayed parameter tensors: 98, with 75,679,232 parameters\n",
            "num non-decayed parameter tensors: 49, with 25,088 parameters\n",
            "using fused AdamW: True\n",
            "step 0: train loss 4.6494, val loss 4.6456\n",
            "iter 0: loss 4.6189, time 8142.25ms, mfu -100.00%\n",
            "iter 200: loss 1.3814, time 725.68ms, mfu 7.11%\n",
            "iter 400: loss 0.9271, time 713.24ms, mfu 7.12%\n",
            "iter 600: loss 0.8645, time 709.39ms, mfu 7.14%\n",
            "iter 800: loss 0.5757, time 725.90ms, mfu 7.13%\n",
            "step 1000: train loss 0.5519, val loss 0.5652\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_runs/out-abc-large\n",
            "iter 1000: loss 0.4072, time 9334.81ms, mfu 6.48%\n",
            "iter 1200: loss 0.5700, time 723.61ms, mfu 6.54%\n",
            "iter 1400: loss 0.5206, time 706.88ms, mfu 6.62%\n",
            "iter 1600: loss 0.5236, time 705.60ms, mfu 6.69%\n",
            "iter 1800: loss 0.4494, time 703.22ms, mfu 6.75%\n",
            "step 2000: train loss 0.4720, val loss 0.4650\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_runs/out-abc-large\n",
            "iter 2000: loss 0.7366, time 9631.18ms, mfu 6.13%\n",
            "iter 2200: loss 0.4732, time 715.46ms, mfu 6.24%\n",
            "iter 2400: loss 0.4808, time 709.61ms, mfu 6.34%\n",
            "iter 2600: loss 0.5237, time 693.17ms, mfu 6.45%\n",
            "iter 2800: loss 0.3908, time 726.72ms, mfu 6.52%\n",
            "step 3000: train loss 0.4497, val loss 0.4412\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_runs/out-abc-large\n",
            "iter 3000: loss 0.4160, time 12090.87ms, mfu 5.91%\n",
            "iter 3200: loss 0.6309, time 726.27ms, mfu 6.03%\n",
            "iter 3400: loss 0.6520, time 712.66ms, mfu 6.15%\n",
            "iter 3600: loss 0.3624, time 694.99ms, mfu 6.28%\n",
            "iter 3800: loss 0.5666, time 709.52ms, mfu 6.37%\n",
            "step 4000: train loss 0.4374, val loss 0.4278\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_runs/out-abc-large\n",
            "iter 4000: loss 0.4263, time 9705.73ms, mfu 5.79%\n",
            "iter 4200: loss 0.3573, time 707.10ms, mfu 5.94%\n",
            "iter 4400: loss 0.5121, time 718.40ms, mfu 6.06%\n",
            "iter 4600: loss 0.4103, time 711.42ms, mfu 6.18%\n",
            "iter 4800: loss 0.5058, time 702.11ms, mfu 6.30%\n",
            "step 5000: train loss 0.4050, val loss 0.4043\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_runs/out-abc-large\n",
            "iter 5000: loss 0.6936, time 9586.87ms, mfu 5.72%\n",
            "iter 5200: loss 0.5549, time 724.21ms, mfu 5.86%\n",
            "iter 5400: loss 0.5564, time 708.23ms, mfu 6.01%\n",
            "iter 5600: loss 0.3853, time 706.29ms, mfu 6.14%\n",
            "iter 5800: loss 0.3966, time 721.50ms, mfu 6.24%\n",
            "step 6000: train loss 0.4224, val loss 0.4073\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_runs/out-abc-large\n",
            "iter 6000: loss 0.4499, time 11903.33ms, mfu 5.66%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/backends/__init__.py:46: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
            "  self.setter(val)\n",
            "/content/nanoGPT/train.py:196: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "cd /content/nanoGPT\n",
        "python -u train.py config/abc_large.py | tee /content/drive/MyDrive/large.log\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FujQ7Jw-747M"
      },
      "source": [
        "XL\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gntrx66N77yU"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "cd /content/nanoGPT\n",
        "cat << 'EOF' > config/abc_xl.py\n",
        "# config/abc_xl.py\n",
        "# XL GPT (~100M parameters) — FINAL, CLEAN, FAIR\n",
        "\n",
        "# -------------------\n",
        "# Output & logging\n",
        "# -------------------\n",
        "out_dir = '/content/drive/MyDrive/nanoGPT_runs/out-abc-xl'\n",
        "eval_interval = 1000\n",
        "eval_iters = 200\n",
        "log_interval = 200\n",
        "always_save_checkpoint = True\n",
        "\n",
        "# -------------------\n",
        "# Dataset\n",
        "# -------------------\n",
        "dataset = 'abc'\n",
        "\n",
        "# -------------------\n",
        "# Batch Settings (CONSISTENT)\n",
        "# -------------------\n",
        "batch_size = 8\n",
        "block_size = 256\n",
        "gradient_accumulation_steps = 32\n",
        "# Tokens / iter = 8 × 256 × 32 = 32768 (same as all models)\n",
        "\n",
        "# -------------------\n",
        "# Model Architecture (XL)\n",
        "# -------------------\n",
        "n_layer = 36\n",
        "n_head  = 20\n",
        "n_embd  = 640\n",
        "dropout = 0.1\n",
        "\n",
        "# -------------------\n",
        "# Training (1 epoch ≈ 200M tokens)\n",
        "# -------------------\n",
        "learning_rate = 3e-4\n",
        "max_iters = 6104\n",
        "lr_decay_iters = max_iters\n",
        "warmup_iters = 500\n",
        "min_lr = 1e-5\n",
        "\n",
        "weight_decay = 1e-1\n",
        "beta1 = 0.9\n",
        "beta2 = 0.95\n",
        "grad_clip = 1.0\n",
        "\n",
        "# -------------------\n",
        "# System\n",
        "# -------------------\n",
        "device = 'cuda'\n",
        "dtype = 'bfloat16'   # A100-safe\n",
        "compile = False      # safer for Colab\n",
        "EOF\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMT6-DUj788W",
        "outputId": "9de16625-d163-4d63-dcec-a8ce7e23076c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overriding config with config/abc_xl.py:\n",
            "# config/abc_xl.py\n",
            "# XL GPT (~100M parameters) — FINAL, CLEAN, FAIR\n",
            "\n",
            "# -------------------\n",
            "# Output & logging\n",
            "# -------------------\n",
            "out_dir = '/content/drive/MyDrive/nanoGPT_runs/out-abc-xl'\n",
            "eval_interval = 1000\n",
            "eval_iters = 200\n",
            "log_interval = 200\n",
            "always_save_checkpoint = True\n",
            "\n",
            "# -------------------\n",
            "# Dataset\n",
            "# -------------------\n",
            "dataset = 'abc'\n",
            "\n",
            "# -------------------\n",
            "# Batch Settings (CONSISTENT)\n",
            "# -------------------\n",
            "batch_size = 8\n",
            "block_size = 256\n",
            "gradient_accumulation_steps = 32\n",
            "# Tokens / iter = 8 × 256 × 32 = 32768 (same as all models)\n",
            "\n",
            "# -------------------\n",
            "# Model Architecture (XL)\n",
            "# -------------------\n",
            "n_layer = 36\n",
            "n_head  = 20\n",
            "n_embd  = 640\n",
            "dropout = 0.1\n",
            "\n",
            "# -------------------\n",
            "# Training (1 epoch ≈ 200M tokens)\n",
            "# -------------------\n",
            "learning_rate = 3e-4\n",
            "max_iters = 6104\n",
            "lr_decay_iters = max_iters\n",
            "warmup_iters = 500\n",
            "min_lr = 1e-5\n",
            "\n",
            "weight_decay = 1e-1\n",
            "beta1 = 0.9\n",
            "beta2 = 0.95\n",
            "grad_clip = 1.0\n",
            "\n",
            "# -------------------\n",
            "# System\n",
            "# -------------------\n",
            "device = 'cuda'\n",
            "dtype = 'bfloat16'   # A100-safe\n",
            "compile = False      # safer for Colab\n",
            "\n",
            "tokens per iteration will be: 65,536\n",
            "found vocab_size = 99 (inside data/abc/meta.pkl)\n",
            "Initializing a new model from scratch\n",
            "number of parameters: 177.06M\n",
            "num decayed parameter tensors: 146, with 177,174,400 parameters\n",
            "num non-decayed parameter tensors: 73, with 46,720 parameters\n",
            "using fused AdamW: True\n",
            "step 0: train loss 4.7195, val loss 4.7221\n",
            "iter 0: loss 4.6645, time 11270.94ms, mfu -100.00%\n",
            "iter 200: loss 1.5370, time 2018.55ms, mfu 11.79%\n",
            "iter 400: loss 0.8757, time 2032.37ms, mfu 11.78%\n",
            "iter 600: loss 0.5336, time 1980.90ms, mfu 11.81%\n",
            "iter 800: loss 0.5643, time 1993.69ms, mfu 11.82%\n",
            "step 1000: train loss 0.5072, val loss 0.4773\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_runs/out-abc-xl\n",
            "iter 1000: loss 0.4700, time 15043.11ms, mfu 10.80%\n",
            "iter 1200: loss 0.6965, time 1955.62ms, mfu 10.93%\n",
            "iter 1400: loss 0.5890, time 2043.99ms, mfu 11.00%\n",
            "iter 1600: loss 0.4120, time 1976.95ms, mfu 11.11%\n",
            "iter 1800: loss 0.5060, time 2015.17ms, mfu 11.18%\n",
            "step 2000: train loss 0.4472, val loss 0.4410\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_runs/out-abc-xl\n",
            "iter 2000: loss 0.5061, time 18228.42ms, mfu 10.19%\n",
            "iter 2200: loss 0.4399, time 2050.54ms, mfu 10.33%\n",
            "iter 2400: loss 0.2908, time 1984.78ms, mfu 10.50%\n",
            "iter 2600: loss 0.4739, time 1979.17ms, mfu 10.65%\n",
            "iter 2800: loss 0.5176, time 2004.91ms, mfu 10.77%\n",
            "step 3000: train loss 0.4194, val loss 0.4053\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_runs/out-abc-xl\n",
            "iter 3000: loss 0.4119, time 16089.92ms, mfu 9.84%\n",
            "iter 3200: loss 0.5110, time 1996.39ms, mfu 10.05%\n",
            "iter 3400: loss 0.4627, time 2004.97ms, mfu 10.23%\n",
            "iter 3600: loss 0.4916, time 1958.58ms, mfu 10.43%\n",
            "iter 3800: loss 0.3743, time 2005.80ms, mfu 10.57%\n",
            "step 4000: train loss 0.3998, val loss 0.4005\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_runs/out-abc-xl\n",
            "iter 4000: loss 0.5103, time 15351.06ms, mfu 9.67%\n",
            "iter 4200: loss 0.5525, time 2005.01ms, mfu 9.89%\n",
            "iter 4400: loss 0.4393, time 1989.06ms, mfu 10.10%\n",
            "iter 4600: loss 0.4510, time 2004.53ms, mfu 10.27%\n",
            "iter 4800: loss 0.4389, time 2004.06ms, mfu 10.43%\n",
            "step 5000: train loss 0.4007, val loss 0.3893\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_runs/out-abc-xl\n",
            "iter 5000: loss 0.3728, time 19262.40ms, mfu 9.51%\n",
            "iter 5200: loss 0.4148, time 1970.02ms, mfu 9.77%\n",
            "iter 5400: loss 0.3584, time 2004.66ms, mfu 9.98%\n",
            "iter 5600: loss 0.4214, time 1980.41ms, mfu 10.18%\n",
            "iter 5800: loss 0.3697, time 1980.52ms, mfu 10.37%\n",
            "step 6000: train loss 0.3971, val loss 0.3869\n",
            "saving checkpoint to /content/drive/MyDrive/nanoGPT_runs/out-abc-xl\n",
            "iter 6000: loss 0.4468, time 15330.35ms, mfu 9.49%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/backends/__init__.py:46: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
            "  self.setter(val)\n",
            "/content/nanoGPT/train.py:196: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "cd /content/nanoGPT\n",
        "python -u train.py config/abc_xl.py | tee /content/drive/MyDrive/xl.log\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
